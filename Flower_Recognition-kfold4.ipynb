{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z19bVm7o9zeu",
    "outputId": "e6607658-c349-4b88-b29b-bf08b229daa7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Ignore  the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    " \n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "% matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "#preprocess.\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#dl libraraies\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# specifically for cnn\n",
    "from keras.layers import Dropout, Flatten,Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
    " \n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "\n",
    "# specifically for manipulating zipped images and getting numpy arrays of pixel values of images.\n",
    "import cv2                  \n",
    "import numpy as np  \n",
    "from tqdm import tqdm\n",
    "import os                   \n",
    "from random import shuffle  \n",
    "from zipfile import ZipFile\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"data/train\"  # Input directory\n",
    "learning_rate = 0.001  # Learning rate\n",
    "opt = \"SGD\"  # Optimizer\n",
    "target_size = (150, 150)  # Target size for data augmentation\n",
    "\n",
    "# Configure a callback to reduce the learning rate upon plateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=50,\n",
    "                              cooldown=50, min_lr=0.0001, verbose=1)\n",
    "\n",
    "# Path to pre-trained weights file, if used. Otherwise None.\n",
    "weights = None\n",
    "\n",
    "# Configure the validation parameters\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Now processing data/train/sunflower/24459750_eb49f6e4cb_m.jpg / sunflower / 0 ...\n",
      "*** Now processing data/train/sunflower/26254755_1bfc494ef1_n.jpg / sunflower / 0 ...\n",
      "*** Now processing data/train/sunflower/27466794_57e4fe5656.jpg / sunflower / 0 ...\n",
      "*** Now processing data/train/sunflower/27465811_9477c9d044.jpg / sunflower / 0 ...\n",
      "*** Now processing data/train/sunflower/6953297_8576bf4ea3.jpg / sunflower / 0 ...\n",
      "*** Now processing data/train/sunflower/24459548_27a783feda.jpg / sunflower / 0 ...\n",
      "*** Now processing data/train/sunflower/29972905_4cc537ff4b_n.jpg / sunflower / 0 ...\n",
      "*** Now processing data/train/tulip/14957470_6a8c272a87_m.jpg / tulip / 1 ...\n",
      "*** Now processing data/train/tulip/11746276_de3dec8201.jpg / tulip / 1 ...\n",
      "*** Now processing data/train/tulip/11746452_5bc1749a36.jpg / tulip / 1 ...\n",
      "*** Now processing data/train/tulip/11746548_26b3256922_n.jpg / tulip / 1 ...\n",
      "*** Now processing data/train/tulip/10791227_7168491604.jpg / tulip / 1 ...\n",
      "*** Now processing data/train/tulip/11746367_d23a35b085_n.jpg / tulip / 1 ...\n",
      "*** Now processing data/train/tulip/11746080_963537acdc.jpg / tulip / 1 ...\n",
      "*** Now processing data/train/daisy/5673728_71b8cb57eb.jpg / daisy / 2 ...\n",
      "*** Now processing data/train/daisy/15207766_fc2f1d692c_n.jpg / daisy / 2 ...\n",
      "*** Now processing data/train/daisy/11642632_1e7627a2cc.jpg / daisy / 2 ...\n",
      "*** Now processing data/train/daisy/5794835_d15905c7c8_n.jpg / daisy / 2 ...\n",
      "*** Now processing data/train/daisy/5547758_eea9edfd54_n.jpg / daisy / 2 ...\n",
      "*** Now processing data/train/daisy/5673551_01d1ea993e_n.jpg / daisy / 2 ...\n",
      "*** Now processing data/train/daisy/5794839_200acd910c_n.jpg / daisy / 2 ...\n",
      "*** Now processing data/train/dandelion/8684108_a85764b22d_n.jpg / dandelion / 3 ...\n",
      "*** Now processing data/train/dandelion/8475758_4c861ab268_m.jpg / dandelion / 3 ...\n",
      "*** Now processing data/train/dandelion/7355522_b66e5d3078_m.jpg / dandelion / 3 ...\n",
      "*** Now processing data/train/dandelion/8181477_8cb77d2e0f_n.jpg / dandelion / 3 ...\n",
      "*** Now processing data/train/dandelion/8223949_2928d3f6f6_n.jpg / dandelion / 3 ...\n",
      "*** Now processing data/train/dandelion/8223968_6b51555d2f_n.jpg / dandelion / 3 ...\n",
      "*** Now processing data/train/dandelion/8475769_3dea463364_m.jpg / dandelion / 3 ...\n",
      "*** Now processing data/train/rose/99383371_37a5ac12a3_n.jpg / rose / 4 ...\n",
      "*** Now processing data/train/rose/118974357_0faa23cce9_n.jpg / rose / 4 ...\n",
      "*** Now processing data/train/rose/123128873_546b8b7355_n.jpg / rose / 4 ...\n",
      "*** Now processing data/train/rose/22679076_bdb4c24401_m.jpg / rose / 4 ...\n",
      "*** Now processing data/train/rose/102501987_3cdb8e5394_n.jpg / rose / 4 ...\n",
      "*** Now processing data/train/rose/110472418_87b6a3aa98_m.jpg / rose / 4 ...\n",
      "*** Now processing data/train/rose/12240303_80d87f77a3_n.jpg / rose / 4 ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up a list for keeping validation scores\n",
    "scores = []\n",
    "\n",
    "# Read data & labels\n",
    "data, labels, classes = [], [], {}\n",
    "\n",
    "for (root, subdirs, files) in os.walk(input_dir):\n",
    "    # Assign a numerical identifier to each class directory\n",
    "    for i, class_dir in enumerate(subdirs):\n",
    "        classes[class_dir] = i\n",
    "\n",
    "    # Define allowed image extensions\n",
    "    ext = ['png', 'jpg', 'jpeg']\n",
    "\n",
    "    # Loop over the files in each directory\n",
    "    for f in files:\n",
    "        if f.split('.')[-1] in ext:  # Check file extension\n",
    "            path = os.path.join(root, f)  # Get image path\n",
    "            label = path.split('/')[-2]  # Extract class label from path\n",
    "            numlabel = classes[label]  # Get numerical label from the dict\n",
    "\n",
    "            print( \"*** Now processing {} / {} / {} ...\".format(path,\n",
    "                                                               label,\n",
    "                                                               numlabel))\n",
    "\n",
    "            # Load and preprocess image\n",
    "            image = load_img(path, target_size=target_size)  # Load image\n",
    "            features = img_to_array(image)  # Convert image to numpy array\n",
    "\n",
    "            labels.append(numlabel)  # Append label to list\n",
    "            data.append(features)  # Append features to list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data and labels to numpy arrays\n",
    "data = np.asarray(data, dtype=np.float32)\n",
    "labels = np.asarray(labels, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 150, 150, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(150, 150,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt= SGD\n",
    "    for n, (train, test) in enumerate(kfold.split(data, labels)):\n",
    "\n",
    "        # Select CNN architecture\n",
    "        model = create_model()\n",
    "        # If selected, configure SGD optimizer\n",
    "        if opt == \"SGD\":\n",
    "            optimizer = SGD(lr=learning_rate, decay=1e-5,\n",
    "                            momentum=0.9, nesterov=True)\n",
    "\n",
    "        # If selected, configure RMSProp optimizer\n",
    "        if opt == \"RMSProp\":\n",
    "            optimizer = RMSprop(lr=learning_rate)\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer,\n",
    "                      metrics=['categorical_accuracy'])\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        traindata, trainlabels = data[train], labels[train]\n",
    "        testdata, testlabels = data[test], labels[test]\n",
    "\n",
    "        # Convert integer labels into one-hot encoded vectors\n",
    "        trainlabels = np_utils.to_categorical(trainlabels, 5)\n",
    "        testlabels = np_utils.to_categorical(testlabels, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2048/2048 [==============================] - 757s 370ms/step - loss: 0.1471 - categorical_accuracy: 0.9473 - val_loss: 0.2920 - val_categorical_accuracy: 0.8000\n",
      "Epoch 2/5\n",
      "2048/2048 [==============================] - 753s 368ms/step - loss: 0.0116 - categorical_accuracy: 0.9967 - val_loss: 0.4107 - val_categorical_accuracy: 0.7000\n",
      "Epoch 3/5\n",
      "2048/2048 [==============================] - 743s 363ms/step - loss: 0.0072 - categorical_accuracy: 0.9980 - val_loss: 1.9612 - val_categorical_accuracy: 0.8000\n",
      "Epoch 4/5\n",
      "2048/2048 [==============================] - 746s 364ms/step - loss: 0.0054 - categorical_accuracy: 0.9983 - val_loss: 1.2849 - val_categorical_accuracy: 0.8000\n",
      "Epoch 5/5\n",
      "2048/2048 [==============================] - 747s 365ms/step - loss: 0.0040 - categorical_accuracy: 0.9987 - val_loss: 2.4646 - val_categorical_accuracy: 0.7000\n",
      "10/10 [==============================] - 0s 4ms/step\n",
      "0.6000 (STDEV 0.0000)\n",
      "Best result for fold 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set up generator for training data\n",
    "training_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                        rotation_range=10,\n",
    "                                        width_shift_range=0.2,\n",
    "                                        height_shift_range=0.05,\n",
    "                                        shear_range=0.2,\n",
    "                                        zoom_range=0.2,\n",
    "                                        horizontal_flip=True,\n",
    "                                        fill_mode='nearest'\n",
    "                                        )\n",
    "\n",
    "# Generate training data\n",
    "training_data = training_generator.flow(traindata,\n",
    "                                        trainlabels,\n",
    "                                        batch_size=256\n",
    "                                        )\n",
    "\n",
    "\n",
    "# Set up generator for validation data\n",
    "validation_generator = ImageDataGenerator(rescale=1./255,\n",
    "                                          rotation_range=10,\n",
    "                                          width_shift_range=0.2,\n",
    "                                          height_shift_range=0.05,\n",
    "                                          shear_range=0.2,\n",
    "                                          zoom_range=0.2,\n",
    "                                          horizontal_flip=True,\n",
    "                                          fill_mode='nearest'\n",
    "                                          )\n",
    "\n",
    "# Generate validation data\n",
    "validation_data = validation_generator.flow(testdata,\n",
    "                                            testlabels,\n",
    "                                            batch_size=32\n",
    "                                            )\n",
    "\n",
    "# Start training the model\n",
    "training = model.fit_generator(training_data,\n",
    "                           steps_per_epoch=2048,\n",
    "                           epochs=5,\n",
    "                           validation_data=validation_data,\n",
    "                           validation_steps=256,\n",
    "                           callbacks=[reduce_lr]\n",
    "                           )\n",
    "\n",
    "# Evaluate the model\n",
    "(loss, accuracy) = model.evaluate(testdata,\n",
    "                              testlabels,\n",
    "                              batch_size=32,\n",
    "                              verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6000000238418579, 0.6000000238418579]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6000 (STDEV 0.0000)\n",
      "Best result for fold 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the scores and the best fold\n",
    "print( \"Best result for fold %s\" % np.argmax(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of scores: 0.600000\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of scores: %.6f\" %  (np.mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STDEV 0.0000\n"
     ]
    }
   ],
   "source": [
    "print( \"STDEV %.4f\" % np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Flower Recognition.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
