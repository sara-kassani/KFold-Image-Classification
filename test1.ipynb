{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sara/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/sara/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/sara/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/sara/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/sara/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/sara/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/sara/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# import the necessary packages\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.utils import to_categorical\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# specifically for cnn\n",
    "from keras.layers import Dropout, Flatten,Activation\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the number of epochs to train for, initial learning rate,\n",
    "# and batch size\n",
    "dataset = 'data'\n",
    "# model_path = 'AllStressesModel_upsdataample_dropout.h5'\n",
    "plot = 'Accuracy_plot_upsample_dropout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# read in data ################################################################\n",
    "# initialize the data and labels\n",
    "print(\"[INFO] loading images...\")\n",
    "data = []\n",
    "labels = []\n",
    " \n",
    "# grab the image paths and randomly shuffle them\n",
    "imagePaths = sorted(list(paths.list_images(dataset)))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the input images\n",
    "for imagePath in imagePaths:\n",
    "    # load the image, pre-process it, and store it in the data list\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.resize(image, (28, 28))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    \n",
    "    # extract the class label from the image path and update the\n",
    "    # labels list\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    if label == 'rose':\n",
    "        label = 0\n",
    "    elif label == 'daisy':\n",
    "        label = 1\n",
    "    elif label == 'tulip':\n",
    "        label = 2\n",
    "    elif label == 'sunflower':\n",
    "        label = 3\n",
    "    elif label == 'dandelion':\n",
    "        label = 4\n",
    "#     elif label == 'PhosphorusDeficiency':\n",
    "#         label = 5\n",
    "#     elif label == 'Rust':\n",
    "#         label = 6\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4323"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4323"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28, 28,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(5))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    return model\n",
    "###############################################################################\n",
    "# train the network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EPOCHS = 15\n",
    "INIT_LR = 1e-3\n",
    "BS = 32\n",
    "\n",
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data,labels, test_size=0.25, random_state=42)\n",
    "\n",
    "# convert the labels from integers to vectors\n",
    "trainY = to_categorical(trainY, num_classes=5)\n",
    "testY = to_categorical(testY, num_classes=5)\n",
    "\n",
    "# construct the image generator for data augmentation\n",
    "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "\n",
    "# # initialize the model\n",
    "# print(\"[INFO] compiling model...\")\n",
    "# model = create_model()\n",
    "# opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "# model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "#     metrics=[\"accuracy\"])\n",
    "\n",
    "# # train the network\n",
    "# print(\"[INFO] training network...\")\n",
    "# H = model.fit_generator(aug.flow(trainX, trainY, batch_size=BS),\n",
    "#     validation_data=(testX, testY), steps_per_epoch=len(trainX) // BS,\n",
    "#     epochs=EPOCHS, verbose=1)\n",
    "\n",
    "# # save the model to disk\n",
    "# print(\"[INFO] serializing network...\")\n",
    "# model.save(\"model.h5\")\n",
    "\n",
    "# # plot the training loss and accuracy\n",
    "# plt.style.use(\"ggplot\")\n",
    "# plt.figure()\n",
    "# N = EPOCHS\n",
    "# plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "# plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "# plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "# plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "# plt.title(\"Training Loss and Accuracy on All Stresses\")\n",
    "# plt.xlabel(\"Epoch #\")\n",
    "# plt.ylabel(\"Loss/Accuracy\")\n",
    "# plt.legend(loc=\"lower left\")\n",
    "# plt.savefig(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.5436 - acc: 0.2792\n",
      "Epoch 2/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2981 - acc: 0.4199\n",
      "Epoch 3/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2362 - acc: 0.4370\n",
      "Epoch 4/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 1.2196 - acc: 0.4659\n",
      "Epoch 5/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 1.1605 - acc: 0.5031\n",
      "Epoch 6/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1224 - acc: 0.5374\n",
      "Epoch 7/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0714 - acc: 0.5597\n",
      "Epoch 8/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0318 - acc: 0.5925\n",
      "Epoch 9/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0194 - acc: 0.5834\n",
      "Epoch 10/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0137 - acc: 0.5870\n",
      "Epoch 11/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9976 - acc: 0.6005\n",
      "Epoch 12/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9524 - acc: 0.6219\n",
      "Epoch 13/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9688 - acc: 0.6227\n",
      "Epoch 14/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9390 - acc: 0.6338\n",
      "Epoch 15/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9314 - acc: 0.6198\n",
      "435/435 [==============================] - 0s 221us/step\n",
      "acc: 58.85%\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/15\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 1.4810 - acc: 0.3283\n",
      "Epoch 2/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2686 - acc: 0.4517\n",
      "Epoch 3/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2112 - acc: 0.4873\n",
      "Epoch 4/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1351 - acc: 0.5364\n",
      "Epoch 5/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0932 - acc: 0.5578\n",
      "Epoch 6/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0525 - acc: 0.5754\n",
      "Epoch 7/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0427 - acc: 0.5795\n",
      "Epoch 8/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0182 - acc: 0.5865\n",
      "Epoch 9/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0094 - acc: 0.5971\n",
      "Epoch 10/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9739 - acc: 0.6100\n",
      "Epoch 11/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9630 - acc: 0.6173\n",
      "Epoch 12/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9783 - acc: 0.6183\n",
      "Epoch 13/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 0.9712 - acc: 0.6196\n",
      "Epoch 14/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9550 - acc: 0.6162\n",
      "Epoch 15/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9342 - acc: 0.6255: 1s - \n",
      "435/435 [==============================] - 0s 245us/step\n",
      "acc: 60.92%\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/15\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 1.4554 - acc: 0.3408\n",
      "Epoch 2/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2777 - acc: 0.4520\n",
      "Epoch 3/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1773 - acc: 0.5041\n",
      "Epoch 4/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1449 - acc: 0.5373\n",
      "Epoch 5/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 1.0924 - acc: 0.5596\n",
      "Epoch 6/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0586 - acc: 0.5740\n",
      "Epoch 7/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0542 - acc: 0.5769\n",
      "Epoch 8/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0328 - acc: 0.5862\n",
      "Epoch 9/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0012 - acc: 0.6027\n",
      "Epoch 10/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9786 - acc: 0.6061\n",
      "Epoch 11/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9696 - acc: 0.6088\n",
      "Epoch 12/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9640 - acc: 0.6218\n",
      "Epoch 13/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9568 - acc: 0.6247\n",
      "Epoch 14/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9271 - acc: 0.6316\n",
      "Epoch 15/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9440 - acc: 0.6334\n",
      "434/434 [==============================] - 0s 301us/step\n",
      "acc: 59.91%\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/15\n",
      "121/121 [==============================] - 2s 16ms/step - loss: 1.4757 - acc: 0.3144\n",
      "Epoch 2/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2762 - acc: 0.4362\n",
      "Epoch 3/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2115 - acc: 0.4772\n",
      "Epoch 4/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 1.1459 - acc: 0.5233\n",
      "Epoch 5/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1047 - acc: 0.5524\n",
      "Epoch 6/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0663 - acc: 0.5802\n",
      "Epoch 7/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0567 - acc: 0.5710\n",
      "Epoch 8/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0149 - acc: 0.5965\n",
      "Epoch 9/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9965 - acc: 0.6072\n",
      "Epoch 10/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0156 - acc: 0.5938\n",
      "Epoch 11/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9650 - acc: 0.6216\n",
      "Epoch 12/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9484 - acc: 0.6296\n",
      "Epoch 13/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9390 - acc: 0.6312\n",
      "Epoch 14/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9249 - acc: 0.6554\n",
      "Epoch 15/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9186 - acc: 0.6412\n",
      "434/434 [==============================] - 0s 336us/step\n",
      "acc: 61.75%\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/15\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 1.4579 - acc: 0.3527\n",
      "Epoch 2/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 1.2787 - acc: 0.4416\n",
      "Epoch 3/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2186 - acc: 0.4840\n",
      "Epoch 4/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1669 - acc: 0.5108\n",
      "Epoch 5/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1059 - acc: 0.5394\n",
      "Epoch 6/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0765 - acc: 0.5769\n",
      "Epoch 7/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0548 - acc: 0.5945\n",
      "Epoch 8/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0197 - acc: 0.5905\n",
      "Epoch 9/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0323 - acc: 0.5925\n",
      "Epoch 10/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0037 - acc: 0.6030\n",
      "Epoch 11/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9733 - acc: 0.6193\n",
      "Epoch 12/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9741 - acc: 0.6158\n",
      "Epoch 13/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9635 - acc: 0.6267\n",
      "Epoch 14/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9520 - acc: 0.6300\n",
      "Epoch 15/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9200 - acc: 0.6452\n",
      "431/431 [==============================] - 0s 370us/step\n",
      "acc: 61.02%\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/15\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 1.4498 - acc: 0.3589\n",
      "Epoch 2/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2521 - acc: 0.4572\n",
      "Epoch 3/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2013 - acc: 0.4820\n",
      "Epoch 4/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1458 - acc: 0.5168\n",
      "Epoch 5/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1192 - acc: 0.5361\n",
      "Epoch 6/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0880 - acc: 0.5491\n",
      "Epoch 7/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 1.0524 - acc: 0.5745\n",
      "Epoch 8/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 1.0399 - acc: 0.5882\n",
      "Epoch 9/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0026 - acc: 0.5991\n",
      "Epoch 10/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9920 - acc: 0.6101\n",
      "Epoch 11/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9961 - acc: 0.6051\n",
      "Epoch 12/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9825 - acc: 0.6095\n",
      "Epoch 13/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9788 - acc: 0.6138\n",
      "Epoch 14/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9582 - acc: 0.6258\n",
      "Epoch 15/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9555 - acc: 0.6183\n",
      "431/431 [==============================] - 0s 393us/step\n",
      "acc: 52.67%\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/15\n",
      "121/121 [==============================] - 2s 17ms/step - loss: 1.4565 - acc: 0.3389\n",
      "Epoch 2/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2787 - acc: 0.4244\n",
      "Epoch 3/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2078 - acc: 0.4708\n",
      "Epoch 4/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1734 - acc: 0.5071\n",
      "Epoch 5/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1105 - acc: 0.5418\n",
      "Epoch 6/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0875 - acc: 0.5628\n",
      "Epoch 7/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0659 - acc: 0.5753\n",
      "Epoch 8/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 1.0236 - acc: 0.5856\n",
      "Epoch 9/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 1.0132 - acc: 0.6041\n",
      "Epoch 10/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 0.9944 - acc: 0.6121\n",
      "Epoch 11/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 0.9873 - acc: 0.6070\n",
      "Epoch 12/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9834 - acc: 0.6134\n",
      "Epoch 13/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9717 - acc: 0.6185\n",
      "Epoch 14/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9554 - acc: 0.6201\n",
      "Epoch 15/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9348 - acc: 0.6395\n",
      "431/431 [==============================] - 0s 422us/step\n",
      "acc: 61.48%\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/15\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 1.4891 - acc: 0.3304\n",
      "Epoch 2/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2778 - acc: 0.4411\n",
      "Epoch 3/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2032 - acc: 0.4842\n",
      "Epoch 4/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1432 - acc: 0.5385\n",
      "Epoch 5/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 1.1173 - acc: 0.5483\n",
      "Epoch 6/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0869 - acc: 0.5668\n",
      "Epoch 7/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 1.0461 - acc: 0.5732\n",
      "Epoch 8/15\n",
      "121/121 [==============================] - 2s 14ms/step - loss: 1.0110 - acc: 0.5894\n",
      "Epoch 9/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0063 - acc: 0.5972\n",
      "Epoch 10/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9837 - acc: 0.6069\n",
      "Epoch 11/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9806 - acc: 0.5994\n",
      "Epoch 12/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9567 - acc: 0.6197\n",
      "Epoch 13/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9502 - acc: 0.6100\n",
      "Epoch 14/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9387 - acc: 0.6173\n",
      "Epoch 15/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9355 - acc: 0.6261\n",
      "431/431 [==============================] - 0s 463us/step\n",
      "acc: 60.79%\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/15\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 1.4788 - acc: 0.3224\n",
      "Epoch 2/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.3096 - acc: 0.4149\n",
      "Epoch 3/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2391 - acc: 0.4636\n",
      "Epoch 4/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1698 - acc: 0.5093\n",
      "Epoch 5/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1425 - acc: 0.5256\n",
      "Epoch 6/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0858 - acc: 0.5660\n",
      "Epoch 7/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0690 - acc: 0.5653\n",
      "Epoch 8/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0422 - acc: 0.5736\n",
      "Epoch 9/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0217 - acc: 0.5836\n",
      "Epoch 10/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0054 - acc: 0.5899\n",
      "Epoch 11/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9825 - acc: 0.6101\n",
      "Epoch 12/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9548 - acc: 0.6180\n",
      "Epoch 13/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9416 - acc: 0.6237\n",
      "Epoch 14/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9380 - acc: 0.6314\n",
      "Epoch 15/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9331 - acc: 0.6361\n",
      "431/431 [==============================] - 0s 524us/step\n",
      "acc: 64.50%\n",
      "[INFO] compiling model...\n",
      "[INFO] training network...\n",
      "Epoch 1/15\n",
      "121/121 [==============================] - 2s 18ms/step - loss: 1.4851 - acc: 0.3200\n",
      "Epoch 2/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2876 - acc: 0.4280\n",
      "Epoch 3/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.2262 - acc: 0.4741\n",
      "Epoch 4/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1598 - acc: 0.5157\n",
      "Epoch 5/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.1026 - acc: 0.5406\n",
      "Epoch 6/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0964 - acc: 0.5602\n",
      "Epoch 7/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0586 - acc: 0.5684\n",
      "Epoch 8/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0397 - acc: 0.5796\n",
      "Epoch 9/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 1.0105 - acc: 0.5992\n",
      "Epoch 10/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9662 - acc: 0.6133\n",
      "Epoch 11/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9713 - acc: 0.6186\n",
      "Epoch 12/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9392 - acc: 0.6350\n",
      "Epoch 13/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9490 - acc: 0.6309\n",
      "Epoch 14/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9402 - acc: 0.6312\n",
      "Epoch 15/15\n",
      "121/121 [==============================] - 2s 15ms/step - loss: 0.9220 - acc: 0.6454\n",
      "430/430 [==============================] - 0s 545us/step\n",
      "acc: 58.60%\n",
      "Done!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
      "60.05% (+/- 2.92%)\n"
     ]
    }
   ],
   "source": [
    "# calculate confusion matrix ##################################################\n",
    "import pandas as pd\n",
    "model = create_model()\n",
    "y_pred = model.predict(testX)\n",
    "y_true = testY.copy()\n",
    "\n",
    "y_pred = pd.DataFrame(y_pred)\n",
    "y_true = pd.DataFrame(y_true)\n",
    "\n",
    "y_pred['class'] = y_pred.idxmax(axis=1)\n",
    "y_true['class'] = y_true.idxmax(axis=1)\n",
    "\n",
    "confusion_matrix(y_true['class'],y_pred['class'])\n",
    "\n",
    "# cross validation ############################################################\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "X = data\n",
    "Y = labels\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits = 10, shuffle = True, random_state = seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X,Y):\n",
    "    \n",
    "    # convert the labels from integers to vectors\n",
    "    trainY = to_categorical(Y[train], num_classes=5)\n",
    "    testY = to_categorical(Y[test], num_classes=5)\n",
    "    \n",
    "    # construct the image generator for data augmentation\n",
    "    aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\n",
    "    height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\n",
    "    horizontal_flip=True, fill_mode=\"nearest\")\n",
    "    print(\"[INFO] compiling model...\")\n",
    "    \n",
    "    model2 = create_model()\n",
    "    \n",
    "    opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "    model2.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    \n",
    "    # train the network\n",
    "    print(\"[INFO] training network...\")\n",
    "    model2.fit_generator(aug.flow(X[train], trainY, batch_size=BS),\n",
    "                            steps_per_epoch=len(X[train]) // BS,\n",
    "                            epochs=EPOCHS, verbose=1)\n",
    "    \n",
    "    scores = model2.evaluate(X[test],testY, verbose = 1)\n",
    "    print(\"%s: %.2f%%\" % (model2.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"Done!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
